{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed96c75-0149-4724-be3b-8b4a0e838cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "import glob\n",
    "import polars as pl\n",
    "import json\n",
    "import re\n",
    "from rasterio.sample import sample_gen\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a206f64-cf57-4257-87da-0780f3f098c1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "basedir = '/mnt/d/readyparams'\n",
    "sp = 'Protonotaria_citrea'.lower()\n",
    "year = '2024'\n",
    "spyear = sp + '_' + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abbe4a-7281-434b-a4b4-a7dac443cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "outputdir = os.path.join(basedir,'ppp_paramsoutput')\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "raster_path = os.path.join(basedir,f\"params_{year}.tif\")\n",
    "presence_csv_dir = os.path.join(basedir,'param_csvs')\n",
    "output_path = os.path.join(outputdir,f\"ppp_param_{spyear}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e993c8-e892-4eda-ac42-dfe6cc0f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Presence Points ===\n",
    "\n",
    "# Find matching files\n",
    "csv_files = glob.glob(os.path.join(presence_csv_dir, f\"*{sp}*.csv\"))\n",
    "\n",
    "dfs = []\n",
    "for file_path in csv_files:\n",
    "    print(f\"Reading: {file_path}\")\n",
    "\n",
    "    # Read CSV\n",
    "    df = pl.read_csv(file_path)\n",
    "    # Extract lon/lat\n",
    "    df = df.with_columns([\n",
    "        pl.col(\".geo\").map_elements(lambda x: json.loads(x)[\"coordinates\"][0], return_dtype=pl.Float64).alias(\"longitude\"),\n",
    "        pl.col(\".geo\").map_elements(lambda x: json.loads(x)[\"coordinates\"][1], return_dtype=pl.Float64).alias(\"latitude\")\n",
    "    ])\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop([\"system:index\", \".geo\"])\n",
    "    \n",
    "    \n",
    "    dfs.append(df)\n",
    "    \n",
    "combined_df = pl.concat(dfs, how='diagonal')\n",
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828e7c3-1750-42a5-ab92-bc3e093b72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3984f-f46b-4096-b00b-5c1a9cb2791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df['label'] = 1\n",
    "\n",
    "combined_df = combined_df.with_columns(\n",
    "    pl.lit(1).alias(\"label\")  # constant string\n",
    ")\n",
    "\n",
    "# === Combine and Train ===\n",
    "#data = pd.concat([presence_data, background_data], ignore_index=True)\n",
    "#data.to_parquet(f\"{spyear}_training_data.parquet\", index=False)\n",
    "X = combined_df.drop(['date', 'day', 'month', 'obs_date', 'observation_date', 'protocol_name', 'scientific_name', 'year', 'longitude', 'latitude', 'label'])\n",
    "predictors = combined_df.drop(['date', 'day', 'month', 'obs_date', 'observation_date', 'protocol_name', 'scientific_name', 'year', 'longitude', 'latitude', 'label']).columns\n",
    "print(predictors)\n",
    "y = combined_df['label']\n",
    "X_scaled = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692f856-2ecb-4fe6-b17d-0fe891fddd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import rasterio\n",
    "\n",
    "# ------------------------\n",
    "# === Helper: Batched Poisson Prediction ===\n",
    "# ------------------------\n",
    "def batched_predict_poisson(model, X, batch_size=100000):\n",
    "    n = X.shape[0]\n",
    "    y_intensity = np.full(n, np.nan)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        end = min(i + batch_size, n)\n",
    "        batch = X[i:end]\n",
    "        \n",
    "        if np.isnan(batch).all():\n",
    "            continue\n",
    "        \n",
    "        valid = ~np.isnan(batch).any(axis=1)\n",
    "        if np.any(valid):\n",
    "            preds = model.predict(batch[valid])\n",
    "            y_intensity[i:end][valid] = preds\n",
    "\n",
    "    y_intensity /= np.nanmax(y_intensity)\n",
    "    return y_intensity\n",
    "\n",
    "def batched_scale(X, scaler, batch_size=100000):\n",
    "    n = X.shape[0]\n",
    "    X_scaled = np.full_like(X, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        end = min(i + batch_size, n)\n",
    "        batch = X[i:end]\n",
    "        \n",
    "        valid = ~np.isnan(batch).any(axis=1)\n",
    "        if np.any(valid):\n",
    "            X_scaled[i:end][valid] = scaler.transform(batch[valid])\n",
    "    \n",
    "    return X_scaled\n",
    "\n",
    "# ------------------------\n",
    "# === 5-Fold Cross-Validation ===\n",
    "# ------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Presence = 1, background = small constant\n",
    "    y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "    \n",
    "    model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "    model.fit(X_train, y_train_poisson)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_intensity = model.predict(X_test)\n",
    "    y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "    \n",
    "    # Metrics\n",
    "    y_pred_bin = (y_pred_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred_bin)\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    \n",
    "    metrics.append({'auc': auc, 'f1': f1, 'precision': precision, 'recall': recall})\n",
    "\n",
    "# Average metrics\n",
    "mean_metrics = {k: np.mean([m[k] for m in metrics]) for k in metrics[0].keys()}\n",
    "print(\"5-Fold CV Mean Metrics:\", mean_metrics)\n",
    "\n",
    "# ------------------------\n",
    "# === Train Final Model on Full Dataset ===\n",
    "# ------------------------\n",
    "y_poisson_full = np.where(y==1, 1.0, 1e-4)\n",
    "final_model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "final_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173bff2-7d68-4f46-b410-26ae58886bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate using Poisson deviance (cross-validation)\n",
    "scores = cross_val_score(model, X, y, scoring=\"neg_mean_poisson_deviance\", cv=5)\n",
    "print(\"Mean Poisson Deviance:\", -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57464e6f-843a-4636-8a1e-24fcfe1ada23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# === Predict Across Raster ===\n",
    "# ------------------------\n",
    "stack = np.stack(bands, axis=-1)  # H x W x bands\n",
    "h, w, b = stack.shape\n",
    "X_raster = stack.reshape(-1, b)\n",
    "X_raster_scaled = batched_scale(X_raster, scaler, batch_size=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01603cf6-cdae-4e0c-9cc3-4ee2179b9699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import gc\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "print(f\"Memory before predict: {process.memory_info().rss / 1e6:.2f} MB\")\n",
    "print(f\"X_batch shape: {X_batch.shape}, dtype: {X_batch.dtype}\")\n",
    "print(f\"Model coef shape: {model.coef_.shape}, intercept shape: {np.shape(model.intercept_)}\")\n",
    "\n",
    "def predict_raster_in_chunks(model, scaler, raster_path, output_path, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Memory-safe raster prediction that works with multi-band rasters and arbitrary window sizes.\n",
    "    Reads, scales, predicts, and writes one window at a time.\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        profile = src.profile.copy()\n",
    "        profile.update(\n",
    "            dtype='float32',\n",
    "            count=1,\n",
    "            compress='lzw',\n",
    "            tiled=True,\n",
    "            blockxsize=128,\n",
    "            blockysize=128\n",
    "        )\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            for _, window in src.block_windows(1):\n",
    "                data = src.read(indexes=list(range(1, src.count + 1)), window=window)\n",
    "                n_bands, h, w = data.shape\n",
    "\n",
    "                # (pixels, bands)\n",
    "                X = np.moveaxis(data, 0, -1).reshape(-1, n_bands)\n",
    "\n",
    "                preds = np.full(X.shape[0], np.nan, dtype=np.float32)\n",
    "\n",
    "                valid = ~np.isnan(X).any(axis=1)\n",
    "\n",
    "                if np.any(valid):\n",
    "                    valid_idx = np.where(valid)[0]\n",
    "\n",
    "                    for start in range(0, len(valid_idx), batch_size):\n",
    "                        end = start + batch_size\n",
    "                        batch_idx = valid_idx[start:end]\n",
    "                        X_batch = scaler.transform(X[batch_idx])\n",
    "\n",
    "                        # Replace this:\n",
    "                        # preds_batch = model.predict(X_batch)\n",
    "\n",
    "                        # With this manual GLM step (linear prediction only)\n",
    "                        raw_pred = X_batch @ model.coef_.T + model.intercept_\n",
    "\n",
    "                        # If Poisson, apply inverse link (exponential)\n",
    "                        preds_batch = np.exp(raw_pred).ravel()\n",
    "\n",
    "                        preds[batch_idx] = preds_batch.astype(np.float32)\n",
    "\n",
    "                preds_2d = preds.reshape((h, w))\n",
    "                dst.write(preds_2d, indexes=1, window=window)\n",
    "\n",
    "                # Clean up\n",
    "                del data, X, preds, preds_2d\n",
    "                gc.collect()\n",
    "\n",
    "    print(f\"✅ Predictions written to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "#suitability = batched_predict_poisson(final_model, X_raster_scaled, batch_size=100000)\n",
    "#suitability = suitability.reshape(h, w)\n",
    "output_path = \"predictions_poisson_2017.tif\"\n",
    "predict_raster_in_chunks(final_model, scaler, raster_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11729e9e-1bef-46cf-b9b3-fa5218c080aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize predictors (important for MaxEnt / Poisson)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Fit Poisson Point Process Model (MaxEnt equivalent) ===\n",
    "# Assign y = 1 for presence, small constant for background\n",
    "y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "\n",
    "poisson_model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "poisson_model.fit(X_train, y_train_poisson)\n",
    "\n",
    "# === Predict on Test Set ===\n",
    "y_pred_intensity = poisson_model.predict(X_test)\n",
    "# Normalize to [0,1] for probability-like output\n",
    "y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "cm = confusion_matrix(y_test, (y_pred_prob >= 0.5).astype(int))\n",
    "report = classification_report(y_test, (y_pred_prob >= 0.5).astype(int))\n",
    "\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# === Predict Across the Raster ===\n",
    "# Stack all bands into one array (H x W x bands)\n",
    "stack = np.stack(bands, axis=-1)  # shape: (H, W, bands)\n",
    "h, w, b = stack.shape\n",
    "\n",
    "X_raster = stack.reshape(-1, b)\n",
    "X_raster_scaled = scaler.transform(X_raster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549a1ba-82a8-4b4a-8b22-94dd3e54cd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "# ------------------------\n",
    "# === 5-Fold Cross-Validation ===\n",
    "# ------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Presence = 1, background = small constant\n",
    "    y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "    \n",
    "    model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "    model.fit(X_train, y_train_poisson)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_intensity = model.predict(X_test)\n",
    "    y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "    \n",
    "    # Metrics\n",
    "    y_pred_bin = (y_pred_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred_bin)\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    \n",
    "    metrics.append({'auc': auc, 'f1': f1, 'precision': precision, 'recall': recall})\n",
    "\n",
    "# Average metrics\n",
    "mean_metrics = {k: np.mean([m[k] for m in metrics]) for k in metrics[0].keys()}\n",
    "print(\"5-Fold CV Mean Metrics:\", mean_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c54cd86-3ae6-4986-a6a5-4332c2bc1250",
   "metadata": {},
   "source": [
    "%%capture\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "tile_size = 512  # or 256 or whatever fits in memory\n",
    "\n",
    "with rasterio.open(output_path, 'w',\n",
    "    driver='GTiff',\n",
    "    height=h,\n",
    "    width=w,\n",
    "    count=1,\n",
    "    dtype='float32',\n",
    "    crs=crs,\n",
    "    transform=transform\n",
    ") as dst:\n",
    "\n",
    "    for row in range(0, h, tile_size):\n",
    "        for col in range(0, w, tile_size):\n",
    "            win_h = min(tile_size, h - row)\n",
    "            win_w = min(tile_size, w - col)\n",
    "            window = Window(col, row, win_w, win_h)\n",
    "\n",
    "            # Extract tile from original raster stack\n",
    "            tile_stack = stack[row:row+win_h, col:col+win_w, :]\n",
    "            flat = tile_stack.reshape(-1, tile_stack.shape[-1])\n",
    "\n",
    "            # Predict on valid pixels\n",
    "            valid = ~np.isnan(flat).any(axis=1)\n",
    "            preds = np.full(flat.shape[0], np.nan)\n",
    "            if np.any(valid):\n",
    "                preds[valid] = model.predict_proba(flat[valid])[:, 1]\n",
    "\n",
    "            # Reshape to tile\n",
    "            tile_pred = preds.reshape(win_h, win_w).astype('float32')\n",
    "\n",
    "            # Write to correct window\n",
    "            dst.write(tile_pred, 1, window=window)\n",
    "\n",
    "\n",
    "print(f\"✅ Saved predicted habitat suitability to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24851bc-d4e5-45dc-8026-260d1076dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19d2c8-97d9-4655-8fa8-130dd3811dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Step 6: Evaluate model\n",
    "# -----------------------------\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature importance\n",
    "importances = model.feature_importances_\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(importances)), importances)\n",
    "plt.title(\"Alpha-Earth Embedding Feature Importance\")\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb5a04-31d1-4770-9357-436d23c1ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ROC AUC (better for presence/background models)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Detailed classification report (precision, recall, F1)\n",
    "report = classification_report(y_test, y_pred, digits=3)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"ROC AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de550571-1ba5-4c53-b1a2-8b22d6e5958d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "auc_scores = cross_val_score(\n",
    "    model, X, y, cv=5, scoring=\"roc_auc\"\n",
    ")\n",
    "print(\"Mean AUC:\", auc_scores.mean())\n",
    "print(\"All AUCs:\", auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecbe65-c79b-42d5-85e9-a9ce6635d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Binary classification example\n",
    "# y_test: true labels\n",
    "# y_pred: predicted labels (not probabilities)\n",
    "\n",
    "mIoU = jaccard_score(y_test, y_pred)  # For binary case\n",
    "print(\"mIoU (Jaccard Index):\", mIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716b9c9-1f63-43d1-93b3-912e36fa4f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "| Metric           | What It Tells You                           | Best Use Case                            |\n",
    "| ---------------- | ------------------------------------------- | ---------------------------------------- |\n",
    "| Accuracy         | Overall correctness                         | Balanced classes                         |\n",
    "| ROC AUC          | How well positives are ranked               | Imbalanced classes (presence/background) |\n",
    "| Confusion Matrix | Distribution of prediction errors           | Diagnostic (where model fails)           |\n",
    "| Precision        | How many predicted presences are correct    | When false positives are costly          |\n",
    "| Recall           | How many real presences were found          | When missing presences is bad            |\n",
    "| F1-score         | Balance between precision and recall        | General performance                      |\n",
    "| Cross-val AUC    | Generalization across multiple folds        | More robust evaluation                   |\n",
    "| mIoU             | Overlap between predicted and real presence | Spatially meaningful accuracy            |\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
