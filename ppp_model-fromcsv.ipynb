{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed96c75-0149-4724-be3b-8b4a0e838cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "from rasterio.sample import sample_gen\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a206f64-cf57-4257-87da-0780f3f098c1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "basedir = 'D:/source/statsandmodels/biodiversity'\n",
    "sp = 'Protonotaria_citrea'\n",
    "year = '2017'\n",
    "spyear = sp + '_' + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89abbe4a-7281-434b-a4b4-a7dac443cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "outputdir = os.path.join(basedir,'ppp_paramsoutput')\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "raster_path = os.path.join(basedir,f\"params_{year}.tif\")\n",
    "presence_csv = os.path.join(basedir,'gbif_species_csvs',f\"{spyear}.csv\")\n",
    "output_path = os.path.join(outputdir,f\"pppparam_{spyear}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e993c8-e892-4eda-ac42-dfe6cc0f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Presence Points ===\n",
    "presence_df = pd.read_csv(presence_csv)\n",
    "gdf = gpd.GeoDataFrame(presence_df, geometry=gpd.points_from_xy(presence_df.Longitude, presence_df.Latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "# === Load Raster ===\n",
    "with rasterio.open(raster_path) as src:\n",
    "    bands = [src.read(i + 1) for i in range(src.count)]  # list of arrays\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "    bounds = src.bounds\n",
    "    gdf = gdf.to_crs(crs)  # Reproject presence points to raster CRS\n",
    "    raster_shape = src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc3984f-f46b-4096-b00b-5c1a9cb2791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extract Environmental Variables at Presence Points ===\n",
    "coords = [(point.x, point.y) for point in gdf.geometry]\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    values = [list(x) for x in src.sample(coords)]\n",
    "presence_data = pd.DataFrame(values, columns=[f'band_{i+1}' for i in range(src.count)])\n",
    "\n",
    "presence_data['label'] = 1\n",
    "\n",
    "# === Sample Background Points ===\n",
    "num_background = 10000\n",
    "xs = np.random.uniform(bounds.left, bounds.right, num_background)\n",
    "ys = np.random.uniform(bounds.bottom, bounds.top, num_background)\n",
    "bg_coords = list(zip(xs, ys))\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    bg_vals = [list(x) for x in src.sample(bg_coords)]\n",
    "\n",
    "background_data = pd.DataFrame(bg_vals, columns=[f'band_{i+1}' for i in range(src.count)])\n",
    "background_data = background_data.dropna()\n",
    "background_data['label'] = 0\n",
    "\n",
    "# === Combine and Train ===\n",
    "data = pd.concat([presence_data, background_data], ignore_index=True)\n",
    "data.to_parquet(f\"{spyear}_training_data.parquet\", index=False)\n",
    "X = data.drop(columns='label')\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c692f856-2ecb-4fe6-b17d-0fe891fddd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Mean Metrics: {'auc': 0.9298875287538607, 'f1': 0.018124676464724813, 'precision': 0.45999999999999996, 'recall': 0.009259259259259259}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import rasterio\n",
    "\n",
    "# ------------------------\n",
    "# === Helper: Batched Poisson Prediction ===\n",
    "# ------------------------\n",
    "def batched_predict_poisson(model, X, batch_size=100000):\n",
    "    n = X.shape[0]\n",
    "    y_intensity = np.full(n, np.nan)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        end = min(i + batch_size, n)\n",
    "        batch = X[i:end]\n",
    "        \n",
    "        if np.isnan(batch).all():\n",
    "            continue\n",
    "        \n",
    "        valid = ~np.isnan(batch).any(axis=1)\n",
    "        if np.any(valid):\n",
    "            preds = model.predict(batch[valid])\n",
    "            y_intensity[i:end][valid] = preds\n",
    "\n",
    "    y_intensity /= np.nanmax(y_intensity)\n",
    "    return y_intensity\n",
    "\n",
    "def batched_scale(X, scaler, batch_size=100000):\n",
    "    n = X.shape[0]\n",
    "    X_scaled = np.full_like(X, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        end = min(i + batch_size, n)\n",
    "        batch = X[i:end]\n",
    "        \n",
    "        valid = ~np.isnan(batch).any(axis=1)\n",
    "        if np.any(valid):\n",
    "            X_scaled[i:end][valid] = scaler.transform(batch[valid])\n",
    "    \n",
    "    return X_scaled\n",
    "\n",
    "# ------------------------\n",
    "# === Prepare Presence and Background Data ===\n",
    "# ------------------------\n",
    "coords = [(point.x, point.y) for point in gdf.geometry]\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    values = [list(x) for x in src.sample(coords)]\n",
    "presence_data = pd.DataFrame(values, columns=[f'band_{i+1}' for i in range(src.count)])\n",
    "presence_data['label'] = 1\n",
    "\n",
    "num_background = 10000\n",
    "xs = np.random.uniform(bounds.left, bounds.right, num_background)\n",
    "ys = np.random.uniform(bounds.bottom, bounds.top, num_background)\n",
    "bg_coords = list(zip(xs, ys))\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    bg_vals = [list(x) for x in src.sample(bg_coords)]\n",
    "background_data = pd.DataFrame(bg_vals, columns=[f'band_{i+1}' for i in range(src.count)])\n",
    "background_data = background_data.dropna()\n",
    "background_data['label'] = 0\n",
    "\n",
    "# Combine\n",
    "data = pd.concat([presence_data, background_data], ignore_index=True)\n",
    "X = data.drop(columns='label').values\n",
    "y = data['label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------------\n",
    "# === 5-Fold Cross-Validation ===\n",
    "# ------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Presence = 1, background = small constant\n",
    "    y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "    \n",
    "    model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "    model.fit(X_train, y_train_poisson)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_intensity = model.predict(X_test)\n",
    "    y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "    \n",
    "    # Metrics\n",
    "    y_pred_bin = (y_pred_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred_bin)\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    \n",
    "    metrics.append({'auc': auc, 'f1': f1, 'precision': precision, 'recall': recall})\n",
    "\n",
    "# Average metrics\n",
    "mean_metrics = {k: np.mean([m[k] for m in metrics]) for k in metrics[0].keys()}\n",
    "print(\"5-Fold CV Mean Metrics:\", mean_metrics)\n",
    "\n",
    "# ------------------------\n",
    "# === Train Final Model on Full Dataset ===\n",
    "# ------------------------\n",
    "y_poisson_full = np.where(y==1, 1.0, 1e-4)\n",
    "final_model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "final_model.fit(X_scaled, y_poisson_full)\n",
    "\n",
    "# ------------------------\n",
    "# === Predict Across Raster ===\n",
    "# ------------------------\n",
    "stack = np.stack(bands, axis=-1)  # H x W x bands\n",
    "h, w, b = stack.shape\n",
    "X_raster = stack.reshape(-1, b)\n",
    "X_raster_scaled = batched_scale(X_raster, scaler, batch_size=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01603cf6-cdae-4e0c-9cc3-4ee2179b9699",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.07 MiB for an array with shape (10000, 14) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#suitability = batched_predict_poisson(final_model, X_raster_scaled, batch_size=100000)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#suitability = suitability.reshape(h, w)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_poisson_2017.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mpredict_raster_in_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraster_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 42\u001b[0m, in \u001b[0;36mpredict_raster_in_chunks\u001b[1;34m(model, scaler, raster_path, output_path, batch_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m         batch_idx \u001b[38;5;241m=\u001b[39m valid_idx[start:end]\n\u001b[0;32m     41\u001b[0m         X_batch \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X[batch_idx])\n\u001b[1;32m---> 42\u001b[0m         preds_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m         preds[batch_idx] \u001b[38;5;241m=\u001b[39m preds_batch\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     45\u001b[0m preds_2d \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mreshape((h, w))\n",
      "File \u001b[1;32mD:\\mambaforge\\envs\\newduckdb\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:360\u001b[0m, in \u001b[0;36m_GeneralizedLinearRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using GLM with feature matrix X.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    Returns predicted values.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# check_array is done in _linear_predictor\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_linear_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(raw_prediction)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32mD:\\mambaforge\\envs\\newduckdb\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:344\u001b[0m, in \u001b[0;36m_GeneralizedLinearRegressor._linear_predictor\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    335\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    336\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    337\u001b[0m     X,\n\u001b[0;32m    338\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m )\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.07 MiB for an array with shape (10000, 14) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import gc\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "print(f\"Memory before predict: {process.memory_info().rss / 1e6:.2f} MB\")\n",
    "print(f\"X_batch shape: {X_batch.shape}, dtype: {X_batch.dtype}\")\n",
    "print(f\"Model coef shape: {model.coef_.shape}, intercept shape: {np.shape(model.intercept_)}\")\n",
    "\n",
    "def predict_raster_in_chunks(model, scaler, raster_path, output_path, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Memory-safe raster prediction that works with multi-band rasters and arbitrary window sizes.\n",
    "    Reads, scales, predicts, and writes one window at a time.\n",
    "    \"\"\"\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        profile = src.profile.copy()\n",
    "        profile.update(\n",
    "            dtype='float32',\n",
    "            count=1,\n",
    "            compress='lzw',\n",
    "            tiled=True,\n",
    "            blockxsize=128,\n",
    "            blockysize=128\n",
    "        )\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            for _, window in src.block_windows(1):\n",
    "                data = src.read(indexes=list(range(1, src.count + 1)), window=window)\n",
    "                n_bands, h, w = data.shape\n",
    "\n",
    "                # (pixels, bands)\n",
    "                X = np.moveaxis(data, 0, -1).reshape(-1, n_bands)\n",
    "\n",
    "                preds = np.full(X.shape[0], np.nan, dtype=np.float32)\n",
    "\n",
    "                valid = ~np.isnan(X).any(axis=1)\n",
    "\n",
    "                if np.any(valid):\n",
    "                    valid_idx = np.where(valid)[0]\n",
    "\n",
    "                    for start in range(0, len(valid_idx), batch_size):\n",
    "                        end = start + batch_size\n",
    "                        batch_idx = valid_idx[start:end]\n",
    "                        X_batch = scaler.transform(X[batch_idx])\n",
    "\n",
    "                        # Replace this:\n",
    "                        # preds_batch = model.predict(X_batch)\n",
    "\n",
    "                        # With this manual GLM step (linear prediction only)\n",
    "                        raw_pred = X_batch @ model.coef_.T + model.intercept_\n",
    "\n",
    "                        # If Poisson, apply inverse link (exponential)\n",
    "                        preds_batch = np.exp(raw_pred).ravel()\n",
    "\n",
    "                        preds[batch_idx] = preds_batch.astype(np.float32)\n",
    "\n",
    "                preds_2d = preds.reshape((h, w))\n",
    "                dst.write(preds_2d, indexes=1, window=window)\n",
    "\n",
    "                # Clean up\n",
    "                del data, X, preds, preds_2d\n",
    "                gc.collect()\n",
    "\n",
    "    print(f\"✅ Predictions written to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "#suitability = batched_predict_poisson(final_model, X_raster_scaled, batch_size=100000)\n",
    "#suitability = suitability.reshape(h, w)\n",
    "output_path = \"predictions_poisson_2017.tif\"\n",
    "predict_raster_in_chunks(final_model, scaler, raster_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11729e9e-1bef-46cf-b9b3-fa5218c080aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize predictors (important for MaxEnt / Poisson)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Fit Poisson Point Process Model (MaxEnt equivalent) ===\n",
    "# Assign y = 1 for presence, small constant for background\n",
    "y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "\n",
    "poisson_model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "poisson_model.fit(X_train, y_train_poisson)\n",
    "\n",
    "# === Predict on Test Set ===\n",
    "y_pred_intensity = poisson_model.predict(X_test)\n",
    "# Normalize to [0,1] for probability-like output\n",
    "y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "cm = confusion_matrix(y_test, (y_pred_prob >= 0.5).astype(int))\n",
    "report = classification_report(y_test, (y_pred_prob >= 0.5).astype(int))\n",
    "\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# === Predict Across the Raster ===\n",
    "# Stack all bands into one array (H x W x bands)\n",
    "stack = np.stack(bands, axis=-1)  # shape: (H, W, bands)\n",
    "h, w, b = stack.shape\n",
    "\n",
    "X_raster = stack.reshape(-1, b)\n",
    "X_raster_scaled = scaler.transform(X_raster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549a1ba-82a8-4b4a-8b22-94dd3e54cd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "# ------------------------\n",
    "# === 5-Fold Cross-Validation ===\n",
    "# ------------------------\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Presence = 1, background = small constant\n",
    "    y_train_poisson = np.where(y_train==1, 1.0, 1e-4)\n",
    "    \n",
    "    model = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "    model.fit(X_train, y_train_poisson)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_intensity = model.predict(X_test)\n",
    "    y_pred_prob = y_pred_intensity / y_pred_intensity.max()\n",
    "    \n",
    "    # Metrics\n",
    "    y_pred_bin = (y_pred_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred_bin)\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    \n",
    "    metrics.append({'auc': auc, 'f1': f1, 'precision': precision, 'recall': recall})\n",
    "\n",
    "# Average metrics\n",
    "mean_metrics = {k: np.mean([m[k] for m in metrics]) for k in metrics[0].keys()}\n",
    "print(\"5-Fold CV Mean Metrics:\", mean_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c54cd86-3ae6-4986-a6a5-4332c2bc1250",
   "metadata": {},
   "source": [
    "%%capture\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "tile_size = 512  # or 256 or whatever fits in memory\n",
    "\n",
    "with rasterio.open(output_path, 'w',\n",
    "    driver='GTiff',\n",
    "    height=h,\n",
    "    width=w,\n",
    "    count=1,\n",
    "    dtype='float32',\n",
    "    crs=crs,\n",
    "    transform=transform\n",
    ") as dst:\n",
    "\n",
    "    for row in range(0, h, tile_size):\n",
    "        for col in range(0, w, tile_size):\n",
    "            win_h = min(tile_size, h - row)\n",
    "            win_w = min(tile_size, w - col)\n",
    "            window = Window(col, row, win_w, win_h)\n",
    "\n",
    "            # Extract tile from original raster stack\n",
    "            tile_stack = stack[row:row+win_h, col:col+win_w, :]\n",
    "            flat = tile_stack.reshape(-1, tile_stack.shape[-1])\n",
    "\n",
    "            # Predict on valid pixels\n",
    "            valid = ~np.isnan(flat).any(axis=1)\n",
    "            preds = np.full(flat.shape[0], np.nan)\n",
    "            if np.any(valid):\n",
    "                preds[valid] = model.predict_proba(flat[valid])[:, 1]\n",
    "\n",
    "            # Reshape to tile\n",
    "            tile_pred = preds.reshape(win_h, win_w).astype('float32')\n",
    "\n",
    "            # Write to correct window\n",
    "            dst.write(tile_pred, 1, window=window)\n",
    "\n",
    "\n",
    "print(f\"✅ Saved predicted habitat suitability to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24851bc-d4e5-45dc-8026-260d1076dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19d2c8-97d9-4655-8fa8-130dd3811dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Step 6: Evaluate model\n",
    "# -----------------------------\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature importance\n",
    "importances = model.feature_importances_\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(importances)), importances)\n",
    "plt.title(\"Alpha-Earth Embedding Feature Importance\")\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb5a04-31d1-4770-9357-436d23c1ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ROC AUC (better for presence/background models)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Detailed classification report (precision, recall, F1)\n",
    "report = classification_report(y_test, y_pred, digits=3)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"ROC AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de550571-1ba5-4c53-b1a2-8b22d6e5958d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "auc_scores = cross_val_score(\n",
    "    model, X, y, cv=5, scoring=\"roc_auc\"\n",
    ")\n",
    "print(\"Mean AUC:\", auc_scores.mean())\n",
    "print(\"All AUCs:\", auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecbe65-c79b-42d5-85e9-a9ce6635d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Binary classification example\n",
    "# y_test: true labels\n",
    "# y_pred: predicted labels (not probabilities)\n",
    "\n",
    "mIoU = jaccard_score(y_test, y_pred)  # For binary case\n",
    "print(\"mIoU (Jaccard Index):\", mIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716b9c9-1f63-43d1-93b3-912e36fa4f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "| Metric           | What It Tells You                           | Best Use Case                            |\n",
    "| ---------------- | ------------------------------------------- | ---------------------------------------- |\n",
    "| Accuracy         | Overall correctness                         | Balanced classes                         |\n",
    "| ROC AUC          | How well positives are ranked               | Imbalanced classes (presence/background) |\n",
    "| Confusion Matrix | Distribution of prediction errors           | Diagnostic (where model fails)           |\n",
    "| Precision        | How many predicted presences are correct    | When false positives are costly          |\n",
    "| Recall           | How many real presences were found          | When missing presences is bad            |\n",
    "| F1-score         | Balance between precision and recall        | General performance                      |\n",
    "| Cross-val AUC    | Generalization across multiple folds        | More robust evaluation                   |\n",
    "| mIoU             | Overlap between predicted and real presence | Spatially meaningful accuracy            |\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
